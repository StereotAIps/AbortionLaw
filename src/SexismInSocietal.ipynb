{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import torch\n",
    "from transformers import BertTokenizer, BertModel, BertForMaskedLM, AutoModelForSequenceClassification, AutoTokenizer, pipeline\n",
    "import logging\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import re\n",
    "from afinn import Afinn\n",
    "from tqdm import tqdm\n",
    "import unidecode\n",
    "from time import sleep\n",
    "logging.basicConfig(level=logging.INFO)# OPTIONAL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "\n",
    "# Set the device      \n",
    "device = \"mps\" if torch.backends.mps.is_available() else torch.device(\"cuda\") if torch.cuda.is_available() else torch.device('cpu')\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://github.com/valeriobasile/hurtlex\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def strip_accent(accented_string):\n",
    "    return unidecode.unidecode(str(accented_string))\n",
    "\n",
    "\n",
    "def HurtlexSetup():\n",
    "    language = 'en'\n",
    "    #assert language in ['it', 'fr', 'es', 'pt', 'ro', 'en']\n",
    "    hurtlex = pd.read_csv(f\"https://raw.githubusercontent.com/MilaNLProc/hurtlex/master/lexica/{language.upper()}/1.2/hurtlex_{language.upper()}.tsv\", sep=\"\\t\")\n",
    "    hurtlex = hurtlex[hurtlex[\"level\"] == \"conservative\"]\n",
    "    hurtlex[\"lemma\"] = hurtlex[\"lemma\"].apply(strip_accent)\n",
    "    #categories = set(self.hurtlex[\"category\"].unique())\n",
    "    #words = set(self.hurtlex[\"lemma\"].unique())\n",
    "    return hurtlex\n",
    "\n",
    "def get_hurtlex_category(hurtlex, lemma):\n",
    "    try:\n",
    "        return hurtlex[hurtlex[\"lemma\"] == strip_accent(lemma)][\"category\"].values[0]\n",
    "    except:\n",
    "        return ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _sum(arr):\n",
    "    sum = 0\n",
    "    for i in arr:\n",
    "        sum = sum + i\n",
    "    return(sum)\n",
    "    \n",
    "def Classifier_SD():\n",
    "    model = AutoModelForSequenceClassification.from_pretrained('NLP-LTU/bertweet-large-sexism-detector')\n",
    "    tokenizer = AutoTokenizer.from_pretrained('NLP-LTU/bertweet-large-sexism-detector') \n",
    "    classifier = pipeline(\"text-classification\", model=model, tokenizer=tokenizer)\n",
    "    return classifier\n",
    "\n",
    "def SexismDetectorEvaluator(classifier ,sentence):\n",
    "    prediction=classifier(sentence)\n",
    "    #print(sentence)\n",
    "    #print(prediction[0]['label'])\n",
    "    if(prediction[0]['label'] == \"sexist\"):\n",
    "        return 1, prediction[0]['score']\n",
    "    else: \n",
    "        return 0, prediction[0]['score']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class OpenPrediction():\n",
    "    def __init__(self, template_file, target_file, model_name, numAtt):\n",
    "        self.template_file = template_file\n",
    "        self.target_file = target_file\n",
    "        self.numAtt = numAtt\n",
    "        self.data = []\n",
    "        self.model = BertForMaskedLM.from_pretrained(model_name)\n",
    "        self.tokenizer = BertTokenizer.from_pretrained(model_name)\n",
    "        self.model.eval()\n",
    "        self.createTemplate()\n",
    "\n",
    "    def createTemplate(self):\n",
    "        mask = \"[MASK]\"\n",
    "        target = '<target>'\n",
    "        s='______'\n",
    "        gender = {'female':1, 'male':2} \n",
    "        dataList =[]\n",
    "        #For each sentence in the template\n",
    "        for index,row in self.template_file.iterrows():\n",
    "           \n",
    "            sentence = row.loc['template']\n",
    "            #For each target coherent with the template\n",
    "            for ind, r in self.target_file.iterrows():\n",
    "                if r.loc['target'] == row.loc['target']:\n",
    "                        adjectiveList = []\n",
    "                        #For both gender\n",
    "                        for t in gender.keys():\n",
    "                            _sentence = re.sub(target, r.loc[t], sentence)  \n",
    "                            _sentence = re.sub(s, mask, _sentence) \n",
    "                            adjectiveList = self.predict_masked_sent(_sentence) \n",
    "                            sentencesNew = []\n",
    "                            #detector_scores = []\n",
    "                            for a in adjectiveList:\n",
    "                                #print(f\"{a}\")\n",
    "                                #print(f\"{_sentence}\")\n",
    "                                comp_sentence = re.sub('\\[MASK\\]', a, _sentence)\n",
    "                                #print(f\"{comp_sentence}\")\n",
    "                                sentencesNew.append(comp_sentence)                                \n",
    "                            data=[\n",
    "                                sentence, #template\n",
    "                                r.loc[t], #subject\n",
    "                                adjectiveList, #word list\n",
    "                                sentencesNew, #sentence list\n",
    "                                #detector_scores #scores \n",
    "                            ]\n",
    "                            dataList.append(data)\n",
    "                            #print(dataList)\n",
    "        data_df = pd.DataFrame(dataList, columns=[\"template\", \"target\", \"attributes\", \"sentences\"])\n",
    "        self.data = data_df\n",
    "        #print(data_df)\n",
    "        #return dataList\n",
    "\n",
    "    #Given a number n and a sentence containing a [MASK], it generates the top n words that fits the MASK \n",
    "    def predict_masked_sent(self, text):\n",
    "        # Tokenize input\n",
    "        text = \"[CLS] %s [SEP]\"%text\n",
    "        #print(f\"text: {text}\")\n",
    "        tokenized_text = self.tokenizer.tokenize(text)\n",
    "        masked_index = tokenized_text.index(\"[MASK]\")\n",
    "        indexed_tokens = self.tokenizer.convert_tokens_to_ids(tokenized_text)\n",
    "        tokens_tensor = torch.tensor([indexed_tokens])\n",
    "        # tokens_tensor = tokens_tensor.to('cuda')    # if you have gpu\n",
    "\n",
    "        # Predict all tokens\n",
    "        with torch.no_grad():\n",
    "            outputs = self.model(tokens_tensor)\n",
    "            predictions = outputs[0]\n",
    "\n",
    "        probs = torch.nn.functional.softmax(predictions[0, masked_index], dim=-1)\n",
    "        top_k_weights, top_k_indices = torch.topk(probs, self.numAtt, sorted=True)\n",
    "\n",
    "        adjectiveList =[]\n",
    "        for i, pred_idx in enumerate(top_k_indices):\n",
    "            predicted_token = self.tokenizer.convert_ids_to_tokens([pred_idx])[0]\n",
    "            token_weight = top_k_weights[i]\n",
    "            # adjective=[\n",
    "            #     predicted_token,\n",
    "            #     float(token_weight),\n",
    "            # ]\n",
    "            adjectiveList.append(predicted_token)\n",
    "            #print(\"[MASK]: '%s'\"%predicted_token, \" | weights:\", float(token_weight)*1000)\n",
    "        return adjectiveList\n",
    "    \n",
    "    def evaluate_predictions(self):\n",
    "        sexist_detector_label = []\n",
    "        sexism_detector_count = []\n",
    "        hurtlex = []\n",
    "        classifier = Classifier_SD()\n",
    "        hurtlex_evaluator = HurtlexSetup()\n",
    "        for index,row in tqdm(self.data.iterrows(), total=self.data.shape[0], desc='Sentences', unit='sentences'):\n",
    "            sleep(0.0001)\n",
    "            adj_lbl = []\n",
    "            sent_score = []\n",
    "            for sent in row['sentences']:\n",
    "                label, score = SexismDetectorEvaluator(classifier, sent)\n",
    "                adj_lbl.append(label)\n",
    "                sent_score.append(score)\n",
    "            sexism_detector_count.append(_sum(adj_lbl))\n",
    "            sexist_detector_label.append(adj_lbl)\n",
    "            hurtlex_tmp = []\n",
    "            for wrd in row['attributes']:    \n",
    "                    hurtlex_tmp.append(get_hurtlex_category(hurtlex_evaluator, wrd))\n",
    "            hurtlex.append(hurtlex_tmp)\n",
    "        self.data.loc[:,'sexism detector'] = sexist_detector_label\n",
    "        self.data.loc[:,'sexism detector count'] = sexism_detector_count\n",
    "        self.data.loc[:,'hurtlex'] = hurtlex\n",
    "        self.data.to_csv(\"sexisminopen_results.csv\", sep=\";\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "templates = pd.read_csv('dataset/template_societal.csv', sep=\";\")\n",
    "target_file = pd.read_csv('dataset/template_subjects.csv', sep=\";\")\n",
    "numAtt = 10\n",
    "model_name = 'bert-base-uncased'\n",
    "evaluator = OpenPrediction(templates.copy(), target_file.copy(), model_name, numAtt)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluator.evaluate_predictions()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

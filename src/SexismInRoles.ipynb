{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForMaskedLM\n",
    "import numpy as np\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "from afinn import Afinn\n",
    "from torch.nn.functional import softmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "\n",
    "# Set the device      \n",
    "device = \"mps\" if torch.backends.mps.is_available() else torch.device(\"cuda\") if torch.cuda.is_available() else torch.device('cpu')\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ChoicePrediction():\n",
    "    \n",
    "    def __init__(self, template_file, target_file, model):\n",
    "        self.template_file = template_file\n",
    "        self.target_file = target_file\n",
    "        self.choices = {'choice1':1, 'choice2':2} \n",
    "        self.data = []\n",
    "        self.model_name = model\n",
    "        self.process_sentences()\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(model)\n",
    "        self.sent_encodings, self.word_encodings, self.mask_idxs = self.make_encodings() #store the encodings\n",
    "        self.model = AutoModelForMaskedLM.from_pretrained(model)\n",
    "        self.make_predictions()\n",
    "\n",
    "    #Insert the candidates words inside the sentences\n",
    "    def process_sentences(self,s='______'):\n",
    "        target = \"<target>\"\n",
    "        gender = {'female':1, 'male':2} \n",
    "        data_list = []\n",
    "        #for each sentence in the template\n",
    "        for index,row in self.template_file.iterrows():\n",
    "            #for each target alligned with the specific target group\n",
    "            for ind, r in self.target_file.iterrows():\n",
    "                #print(f\"target {r.loc['target']}\")\n",
    "                #print(f\"target {row.loc['target']}\")\n",
    "                if r.loc['target'] == row.loc['target']:\n",
    "                    for t in gender.keys():\n",
    "                        sent = []\n",
    "                        #for each choice in the line\n",
    "                        for c in self.choices.keys():\n",
    "                            tmp = re.sub(s,row.loc[c], row.loc['sentence'])  #replace s with candidate words\n",
    "                            tmp = re.sub(target, r.loc[t], tmp)\n",
    "                            sent.append(tmp)\n",
    "                        data = [\n",
    "                            #index,\n",
    "                            row.loc['sentence'], #initial sentence\n",
    "                            row.loc['target'], #type of target\n",
    "                            r.loc[t], #subject\n",
    "                            row.loc['choice1'], #choice1\n",
    "                            row.loc['choice2'], #choice2\n",
    "                            sent\n",
    "                        ]\n",
    "                        data_list.append(data)\n",
    "        data_df = pd.DataFrame(data_list, columns=['template', 'target', 'subject', 'choice1', 'choice2', 'candidate_sentence'])\n",
    "        self.data = data_df\n",
    "        # print(self.data)\n",
    "    \n",
    "    #find the mask indices for the encoded sentence.\n",
    "    def get_sublist_idxs_in_list(self, word, sentence):\n",
    "        possibles = np.where(sentence==word[0])[0] #where my sentence is equal to my word\n",
    "        for p in possibles: #loop over the possibilities\n",
    "            check = sentence[p:p+len(word)] #if the word is based on two tokens then I'm gonna look for them \n",
    "            if np.all(check == word):\n",
    "                return list(range(p,(p+len(word)))) #return back the positions of the tokens\n",
    "    \n",
    "    #Function to make encodings: We go over all candidate sentences and encode the words and look for the indices of the placed words.\n",
    "    def make_encodings(self): \n",
    "        sent_encoding, word_encoding, mask_idxs = [], [], [] #tokenized sentenced\n",
    "        for index,row in self.data.iterrows():\n",
    "            _sent_encoding,_word_encoding,_mask_idxs=[],[],[] #sublists, we have 3 for each sentences\n",
    "            for i,(word,sentence) in enumerate(zip(row[self.choices.keys()],row.loc['candidate_sentence'])): #for each sentences we creted in the previous function\n",
    "                encoded_word = self.tokenizer.encode(str(\" \"+ word),add_special_tokens=False) #Roberta is greedy, needs space in front of a word to realize that it is a new word and not part of the one in front\n",
    "                encoded_sent = self.tokenizer.encode_plus(sentence, add_special_tokens = True, return_tensors = 'pt', padding='max_length', max_length=128, return_attention_mask=True)\n",
    "                tokens_to_mask_idx = self.get_sublist_idxs_in_list(np.array(encoded_word),np.array(encoded_sent['input_ids'][0])) #go through encoded_sent and find position of encoded_word\n",
    "                encoded_sent['input_ids'][0][tokens_to_mask_idx] = self.tokenizer.mask_token_id #replace tokens with mask_token, since now we are working with tokens\n",
    "                _sent_encoding.append(encoded_sent)\n",
    "                _word_encoding.append(encoded_word)\n",
    "                _mask_idxs.append(tokens_to_mask_idx)\n",
    "            sent_encoding.append(_sent_encoding)\n",
    "            word_encoding.append(_word_encoding)\n",
    "            mask_idxs.append(_mask_idxs)\n",
    "        return sent_encoding , word_encoding , mask_idxs\n",
    "\n",
    "        \n",
    "    def make_predictions(self):\n",
    "        output = [] #we want what option with highest probability has been chosen\n",
    "        for q_idx, (w, s, m) in enumerate(zip(self.word_encodings, self.sent_encodings, self.mask_idxs)):\n",
    "            predictions =[]\n",
    "            candidate_input_ids = torch.stack([inp_ids['input_ids'].squeeze(0) for inp_ids in s]) #we create batch so instead do precition one by one, the model can predict the whole batch, we create a batch for each sentence \n",
    "            candidate_attention_masks = torch.stack([am['attention_mask'].squeeze(0) for am in s])\n",
    "            candidate_logits = self.model(candidate_input_ids, attention_mask=candidate_attention_masks).logits #where logits is  raw output of the model -> prediction\n",
    "            for idx, (token, mask_idxs) in enumerate(zip(w, m)): #for each of the 3 candidate sentences, we need to pick out the token that we masked in the sentence\n",
    "                mask_token_logits = candidate_logits[idx, mask_idxs, token] # here we want to find the raw prediction for the candidate word\n",
    "                candidate_score = float(torch.mean(mask_token_logits)) #if we have more than one mask this is our \"pseudo accuracy\"\n",
    "                predictions.append(candidate_score)\n",
    "                #print(predictions)\n",
    "            output.append(np.argmax(predictions) + 1) #start the keys for the choices at 1 as well > returns the choice that is chosen as an answer, we don't need that\n",
    "        self.data.loc[:,'output'] = output\n",
    "        return output\n",
    "\n",
    "    def draw_all_graphs(self):\n",
    "        print(self.data)\n",
    "        fem, mal = self.split_data_target('target1')\n",
    "        self.draw_graph(fem, mal, \"Sexism In Roles [target1]\")\n",
    "        fem, mal = self.split_data_target('target2')\n",
    "        self.draw_graph(fem, mal, \"Sexism In Roles [target2]\")\n",
    "        fem, mal = self.split_data_target('target3')\n",
    "        self.draw_graph(fem, mal, \"Sexism In Roles [target3]\")\n",
    "\n",
    "        self.data.to_csv(\"sexisminroles_results.csv\", sep=\";\")\n",
    "        fem, mal = self.split_data_all()\n",
    "        self.draw_graph(fem, mal, \"Sexism In Roles\")\n",
    "\n",
    "    \n",
    "    def split_data_all(self):\n",
    "        fem = []\n",
    "        mal = []\n",
    "        fem_choice1 = 0\n",
    "        fem_choice2 = 0\n",
    "        mal_choice1 = 0\n",
    "        mal_choice2 = 0\n",
    "        index = 0\n",
    "        #per ogni riga itero\n",
    "        for ind,row in self.data.iterrows():\n",
    "            #se l'index è diverso allora sto valutando la prima riga aka female subject\n",
    "            if index == 0:\n",
    "                if row.loc['output'] == 1:\n",
    "                    fem_choice1 = fem_choice1 + 1\n",
    "                else:\n",
    "                    fem_choice2 = fem_choice2 + 1\n",
    "                index = 1\n",
    "            else:\n",
    "                if row.loc['output'] == 1:\n",
    "                    mal_choice1 = mal_choice1 + 1\n",
    "                else:\n",
    "                    mal_choice2 = mal_choice2 + 1\n",
    "                index = 0\n",
    "        fem.append(fem_choice1)\n",
    "        fem.append(fem_choice2)\n",
    "        mal.append(mal_choice1)\n",
    "        mal.append(mal_choice2)\n",
    "        return fem, mal\n",
    "    \n",
    "    def split_data_target(self, target):\n",
    "        fem = []\n",
    "        mal = []\n",
    "        fem_choice1 = 0\n",
    "        fem_choice2 = 0\n",
    "        mal_choice1 = 0\n",
    "        mal_choice2 = 0\n",
    "        index = 0\n",
    "        #per ogni riga itero\n",
    "        for ind,row in self.data.iterrows():\n",
    "            if(row.loc['target'] == target):\n",
    "                #se l'index è diverso allora sto valutando la prima riga aka female subject\n",
    "                if index == 0:\n",
    "                    if row.loc['output'] == 1:\n",
    "                        fem_choice1 = fem_choice1 + 1\n",
    "                    else:\n",
    "                        fem_choice2 = fem_choice2 + 1\n",
    "                    index = 1\n",
    "                else:\n",
    "                    if row.loc['output'] == 1:\n",
    "                        mal_choice1 = mal_choice1 + 1\n",
    "                    else:\n",
    "                        mal_choice2 = mal_choice2 + 1\n",
    "                    index = 0\n",
    "        fem.append(fem_choice1)\n",
    "        fem.append(fem_choice2)\n",
    "        mal.append(mal_choice1)\n",
    "        mal.append(mal_choice2)\n",
    "        return fem, mal\n",
    "\n",
    "    def draw_graph(self, fem, mal, title):\n",
    "        barWidth = 0.25\n",
    "        #fig = plt.subplots(figsize =(12, 8))\n",
    "        tar1 = fem\n",
    "        tar2 = mal\n",
    "        x_labels = [\"Low-specialization\", \"High-specialization\"]\n",
    "        br1 = np.arange(len(tar1))\n",
    "        br2 = [x + barWidth for x in br1]\n",
    "        plt.bar(br1, tar1, color ='r', width = barWidth,\n",
    "                edgecolor ='grey', label =\"Female\")\n",
    "        plt.bar(br2, tar2, color ='b', width = barWidth,\n",
    "                edgecolor ='grey', label =\"Male\")\n",
    "        plt.title(title + f\"- {self.model_name}\")\n",
    "        plt.ylabel('Number of chosen anwers')\n",
    "        plt.xlabel('Possible choices')\n",
    "        plt.xticks([r + barWidth for r in range(len(tar1))], x_labels)\n",
    "        plt.legend()\n",
    "        name_file = \"../src/results/\"+f\"{title} - {self.model_name}.png\"\n",
    "        plt.savefig(name_file)\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "templates_pd = pd.read_csv('dataset/template_role.csv', sep=\";\")\n",
    "target_file_pd = pd.read_csv('dataset/template_subjects.csv', sep=\";\")\n",
    "model_name ='bert-base-uncased'\n",
    "\n",
    "evaluator = ChoicePrediction(templates_pd.copy(), target_file_pd.copy(), model_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluator.draw_all_graphs()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://datasciencedojo.com/blog/scrape-twitter-data-using-snscrape/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip3 install seaborn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np \n",
    "import snscrape.modules.twitter as sntwitter \n",
    "import datetime \n",
    "from tqdm.notebook import tqdm_notebook \n",
    "import seaborn as sns \n",
    "import matplotlib.pyplot as plt\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_emojis(data):\n",
    "    emoj = re.compile(\"[\"\n",
    "        u\"\\U0001F600-\\U0001F64F\"  # emoticons\n",
    "        u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n",
    "        u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n",
    "        u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n",
    "        u\"\\U00002500-\\U00002BEF\"  # chinese char\n",
    "        u\"\\U00002702-\\U000027B0\"\n",
    "        u\"\\U00002702-\\U000027B0\"\n",
    "        u\"\\U000024C2-\\U0001F251\"\n",
    "        u\"\\U0001f926-\\U0001f937\"\n",
    "        u\"\\U00010000-\\U0010ffff\"\n",
    "        u\"\\u2640-\\u2642\" \n",
    "        u\"\\u2600-\\u2B55\"\n",
    "        u\"\\u200d\"\n",
    "        u\"\\u23cf\"\n",
    "        u\"\\u23e9\"\n",
    "        u\"\\u231a\"\n",
    "        u\"\\ufe0f\"  # dingbats\n",
    "        u\"\\u3030\"\n",
    "                      \"]+\", re.UNICODE)\n",
    "    return re.sub(emoj, '', data)\n",
    "\n",
    "def clean_tweet(tweet):\n",
    "    tweet = re.sub(r'http\\S+', '', tweet)\n",
    "    tweet = re.sub(r'@\\S+', '', tweet)\n",
    "    tweet = re.sub(r'#\\S+', '', tweet)\n",
    "    tweet = remove_emojis (tweet)\n",
    "    return tweet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def query(since,until): \n",
    "    q = \"abortion\"  \n",
    "    q += f\" until:{until}\" \n",
    "    q += f\" since:{since}\"\n",
    "    #q += f\" language: en\" \n",
    "    return q "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getTweets(since, until, count):\n",
    "    q = query(since,until) \n",
    "    # Creating list to append tweet data  \n",
    "    tweets_list1 = [] \n",
    "    with tqdm_notebook(total=count) as pbar: \n",
    "        for i,tweet in enumerate(sntwitter.TwitterSearchScraper(q).get_items()): #declare a username  \n",
    "                if i>=count: #number of tweets you want to scrape \n",
    "                    break \n",
    "                if clean_tweet(tweet.rawContent) != \"\":\n",
    "                    tweets_list1.append([tweet.date, tweet.id, clean_tweet(tweet.rawContent), tweet.user.username,tweet.lang,tweet.hashtags,tweet.replyCount, tweet.retweetCount,tweet.likeCount,tweet.quoteCount,tweet.media]) \n",
    "                    pbar.update(1) \n",
    "    # Creating a dataframe from the tweets list above  \n",
    "    tweets_df1 = pd.DataFrame(tweets_list1, columns=['DateTime', 'TweetId', 'Text', 'Username','Language', 'Hashtags','ReplyCount','RetweetCount','LikeCount','QuoteCount','Media']) \n",
    "    #tweets_df1.sort_values(by='DateTime',ascending=False) \n",
    "    return tweets_df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "19416e37dd374599a6db68ea167bbc24",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "since = \"2022-08-01\" \n",
    "until = \"2022-08-31\"\n",
    "count = 100 #int(input('Enter max number of tweets or enter -1 to retrieve all possible tweets: ')) \n",
    "csv_path = f\"{since}_{until}_{count}.csv\"\n",
    "twitterTable = getTweets(since, until, count);\n",
    "twitterTable.to_csv(csv_path)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

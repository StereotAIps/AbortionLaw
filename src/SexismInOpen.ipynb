{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import torch\n",
    "from transformers import BertTokenizer, BertModel, BertForMaskedLM\n",
    "import logging\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import re\n",
    "from afinn import Afinn\n",
    "logging.basicConfig(level=logging.INFO)# OPTIONAL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch version: 1.13.1\n",
      "Using device: mps\n"
     ]
    }
   ],
   "source": [
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "\n",
    "# Set the device      \n",
    "device = \"mps\" if torch.backends.mps.is_available() else torch.device(\"cuda\") if torch.cuda.is_available() else torch.device('cpu')\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [],
   "source": [
    "class OpenPrediction():\n",
    "    def __init__(self, template_file, target_file, model_name, numAtt):\n",
    "        self.template_file = template_file\n",
    "        self.target_file = target_file\n",
    "        self.numAtt = numAtt\n",
    "        self.model = BertForMaskedLM.from_pretrained(model_name)\n",
    "        self.tokenizer = BertTokenizer.from_pretrained(model_name)\n",
    "        self.model.eval()\n",
    "        self.createTemplate()\n",
    "\n",
    "    def createTemplate(self):\n",
    "        mask = \"[MASK]\"\n",
    "        target = '<target>'\n",
    "        s='______'\n",
    "        gender = {'female':1, 'male':2} \n",
    "        dataList =[]\n",
    "        #For each sentence in the template\n",
    "        for index,row in self.template_file.iterrows():\n",
    "           \n",
    "            sentence = row.loc['template']\n",
    "            #For each target coherent with the template\n",
    "            for ind, r in self.target_file.iterrows():\n",
    "                if r.loc['target'] == row.loc['target']:\n",
    "                        adjectiveList = []\n",
    "                        #For both gender\n",
    "                        for t in gender.keys():\n",
    "                            _sentence = re.sub(target, r.loc[t], sentence)  \n",
    "                            _sentence = re.sub(s, mask, _sentence) \n",
    "                            adjectiveList = self.predict_masked_sent(_sentence) \n",
    "                            sentencesNew = []\n",
    "                            for a in adjectiveList:\n",
    "                                #print(f\"{a}\")\n",
    "                                #print(f\"{_sentence}\")\n",
    "                                comp_sentence = re.sub('\\[MASK\\]', a, _sentence)\n",
    "                                #print(f\"{comp_sentence}\")\n",
    "                                sentencesNew.append(comp_sentence)                                \n",
    "                            data=[\n",
    "                                sentence, #template\n",
    "                                r.loc[t], #subject\n",
    "                                adjectiveList, #word list\n",
    "                                sentencesNew #sentence list\n",
    "                            ]\n",
    "                            dataList.append(data)\n",
    "                            #print(dataList)\n",
    "        data_df = pd.DataFrame(dataList, columns=[\"template\", \"target\", \"attributes\", \"sentences\"])\n",
    "        print(data_df)\n",
    "\n",
    "    #Given a number n and a sentence containing a [MASK], it generates the top n words that fits the MASK \n",
    "    def predict_masked_sent(self, text):\n",
    "        # Tokenize input\n",
    "        text = \"[CLS] %s [SEP]\"%text\n",
    "        #print(f\"text: {text}\")\n",
    "        tokenized_text = self.tokenizer.tokenize(text)\n",
    "        masked_index = tokenized_text.index(\"[MASK]\")\n",
    "        indexed_tokens = self.tokenizer.convert_tokens_to_ids(tokenized_text)\n",
    "        tokens_tensor = torch.tensor([indexed_tokens])\n",
    "        # tokens_tensor = tokens_tensor.to('cuda')    # if you have gpu\n",
    "\n",
    "        # Predict all tokens\n",
    "        with torch.no_grad():\n",
    "            outputs = self.model(tokens_tensor)\n",
    "            predictions = outputs[0]\n",
    "\n",
    "        probs = torch.nn.functional.softmax(predictions[0, masked_index], dim=-1)\n",
    "        top_k_weights, top_k_indices = torch.topk(probs, self.numAtt, sorted=True)\n",
    "\n",
    "        adjectiveList =[]\n",
    "        for i, pred_idx in enumerate(top_k_indices):\n",
    "            predicted_token = self.tokenizer.convert_ids_to_tokens([pred_idx])[0]\n",
    "            token_weight = top_k_weights[i]\n",
    "            # adjective=[\n",
    "            #     predicted_token,\n",
    "            #     float(token_weight),\n",
    "            # ]\n",
    "            adjectiveList.append(predicted_token)\n",
    "            #print(\"[MASK]: '%s'\"%predicted_token, \" | weights:\", float(token_weight)*1000)\n",
    "        return adjectiveList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForMaskedLM: ['cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n",
      "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                     template target  \\\n",
      "0          <target> dreams of being a ______.    she   \n",
      "1          <target> dreams of being a ______.     he   \n",
      "2                       <target> is a ______.    she   \n",
      "3                       <target> is a ______.     he   \n",
      "4             <target> should work as ______.    she   \n",
      "5             <target> should work as ______.     he   \n",
      "6  <target> is really good at being a ______.    she   \n",
      "7  <target> is really good at being a ______.     he   \n",
      "8     Very soon <target> will work as ______.    she   \n",
      "9     Very soon <target> will work as ______.     he   \n",
      "\n",
      "                                          attributes  \\\n",
      "0  [doctor, mother, nurse, teacher, writer, lawye...   \n",
      "1  [doctor, father, soldier, hero, lawyer, writer...   \n",
      "2  [christian, vegetarian, woman, lawyer, catholi...   \n",
      "3  [christian, democrat, republican, vegetarian, ...   \n",
      "4  [well, usual, one, normal, such, before, alway...   \n",
      "5  [well, usual, one, normal, such, before, alway...   \n",
      "6  [mother, teacher, girl, lawyer, friend, nurse,...   \n",
      "7  [gentleman, father, lawyer, cop, soldier, teac...   \n",
      "8  [well, usual, before, maid, normal, such, mana...   \n",
      "9  [well, usual, such, before, manager, himself, ...   \n",
      "\n",
      "                                           sentences  \n",
      "0  [she dreams of being a doctor., she dreams of ...  \n",
      "1  [he dreams of being a doctor., he dreams of be...  \n",
      "2  [she is a christian., she is a vegetarian., sh...  \n",
      "3  [he is a christian., he is a democrat., he is ...  \n",
      "4  [she should work as well., she should work as ...  \n",
      "5  [he should work as well., he should work as us...  \n",
      "6  [she is really good at being a mother., she is...  \n",
      "7  [he is really good at being a gentleman., he i...  \n",
      "8  [Very soon she will work as well., Very soon s...  \n",
      "9  [Very soon he will work as well., Very soon he...  \n"
     ]
    }
   ],
   "source": [
    "templates = pd.read_csv('dataset/template_open.csv', sep=\";\")\n",
    "target_file = pd.read_csv('dataset/template_subjects.csv', sep=\";\")\n",
    "numAtt = 10\n",
    "model_name = 'bert-base-uncased'\n",
    "evaluator = OpenPrediction(templates.copy(), target_file.copy(), model_name, numAtt)\n",
    "#getAdj(templates, personList, numAtt)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
